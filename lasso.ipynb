{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74fb022d",
   "metadata": {},
   "source": [
    "# Implementing Lasso and inductive conformal predictor \n",
    "\n",
    "This assignment includes exploring and predicting data for the diabetes dataset (https://trevorhastie.github.io/data.html):\n",
    "\n",
    "## Table of contents :\n",
    "### 1. Implementing Lasso\n",
    "1.1 Loading the dataset (Task 1)<br>\n",
    "1.2 Splitting the dataset (Task 2)<br>\n",
    "1.3 Computing R^2 for default parameters (Task 3) <br>\n",
    "1.4 Loading/ Splitting the unnormalised dataset (Task 4, 5) <br>\n",
    "1.5 Computing R^2 for default parameters (Task 6)<br>\n",
    "1.6 Preprocessing data using StandardScaler (Task 7)<br>\n",
    "1.7 Observation (Task 8)<br>\n",
    "1.8 Computing R^2 for varying alpha values (Task 9)<br>\n",
    "1.9 Obtaining optimum alpha using cross validation (Task 10)<br>\n",
    "\n",
    "### 2. Implementing the inductive conformal predictor (Task 11)\n",
    "2.1 Splitting dataset<br>\n",
    "2.2 Preprocessing data using StandardScaler<br>\n",
    "2.3 Calculating prediction intervals and error rates<br>\n",
    "\n",
    "### 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1054c3d",
   "metadata": {},
   "source": [
    "# 1. Implementing Lasso\n",
    "\n",
    "### 1.1 Loading the dataset (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb6573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba953c",
   "metadata": {},
   "source": [
    "### 1.2 Splitting the dataset (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8cb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, random_state=2110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe953d",
   "metadata": {},
   "source": [
    "### 1.3 Computing R^2 for default parameters (Task 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b6630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for the default dataset in sklearn\n",
      "\n",
      "Feature names in the dataset:\n",
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "\n",
      "Coefficient list after fitting the training set:\n",
      "[  0.          -0.         332.68237952   0.           0.\n",
      "   0.          -0.           0.         382.35131149   0.        ]\n",
      "\n",
      "Lasso score for training dataset:\n",
      "0.3779757862584656\n",
      "\n",
      "Lasso score for test dataset:\n",
      "0.33115694449502453\n",
      "\n",
      "Final feature list as computed by Lasso:\n",
      "['bmi', 's5']\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing for the default dataset in sklearn\")\n",
    "print()\n",
    "lasso = Lasso()\n",
    "print(\"Feature names in the dataset:\")\n",
    "print(diabetes.feature_names)\n",
    "print()\n",
    "lasso.fit(X_train,y_train)\n",
    "print(\"Coefficient list after fitting the training set:\")\n",
    "print(lasso.coef_)\n",
    "print()\n",
    "print(\"Lasso score for training dataset:\")\n",
    "print(lasso.score(X_train,y_train))\n",
    "print()\n",
    "print(\"Lasso score for test dataset:\")\n",
    "print(lasso.score(X_test,y_test))\n",
    "print()\n",
    "featureList = [ diabetes.feature_names[feature] for feature in np.where(lasso.coef_ != 0)[0] ] \n",
    "print(\"Final feature list as computed by Lasso:\")\n",
    "print(featureList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781cffd6",
   "metadata": {},
   "source": [
    "### 1.4 Loading/ Splitting the unnormalised dataset (Task 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30e1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeDataset = np.genfromtxt('diabetes.txt', delimiter = \"\\t\", skip_header = 1)\n",
    "features = completeDataset[:,:-1]\n",
    "labels = completeDataset[:, -1]\n",
    "X_trainNew, X_testNew, y_trainNew, y_testNew = train_test_split(features, labels, random_state=2110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea782ed",
   "metadata": {},
   "source": [
    "### 1.5 Computing R^2 for default parameters (Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3433e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for the dataset given at https://trevorhastie.github.io/data.html\n",
      "\n",
      "Feature names in the dataset:\n",
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "\n",
      "Coefficient list after fitting the training set:\n",
      "[  0.01840324 -18.11347446   5.43970493   0.84284546   0.09642991\n",
      "  -0.18189383  -1.25073496   0.          41.82569934   0.40685316]\n",
      "\n",
      "Lasso score for training dataset:\n",
      "0.5226383603039815\n",
      "\n",
      "Lasso score for test dataset:\n",
      "0.46347459731826823\n",
      "\n",
      "Final feature list as computed by Lasso:\n",
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing for the dataset given at https://trevorhastie.github.io/data.html\")\n",
    "print()\n",
    "lassoNew = Lasso()\n",
    "print(\"Feature names in the dataset:\")\n",
    "print(diabetes.feature_names)\n",
    "print()\n",
    "lassoNew.fit(X_trainNew,y_trainNew)\n",
    "print(\"Coefficient list after fitting the training set:\")\n",
    "print(lassoNew.coef_)\n",
    "print()\n",
    "print(\"Lasso score for training dataset:\")\n",
    "print(lassoNew.score(X_trainNew,y_trainNew))\n",
    "print()\n",
    "print(\"Lasso score for test dataset:\")\n",
    "print(lassoNew.score(X_testNew,y_testNew))\n",
    "print()\n",
    "featureListNew = [ diabetes.feature_names[feature] for feature in np.where(lassoNew.coef_ != 0)[0] ] \n",
    "print(\"Final feature list as computed by Lasso:\")\n",
    "print(featureListNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9e4d8",
   "metadata": {},
   "source": [
    "Upon observing the list of coefficients obtained in both the datasets and their respective coefficients we can comment that Lasso is more effecient on scaled data and gives a smaller list of features when the data has low variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5802a",
   "metadata": {},
   "source": [
    "### 1.6 Preprocessing data using StandardScaler (Task 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db20c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between scaled data and original data: \n",
      "\n",
      "Scaled data: \n",
      "\n",
      "[[ 0.10225232 -0.93844649 -0.99792994 ... -0.84403969 -1.04672254\n",
      "  -1.27174072]\n",
      " [-1.12849375 -0.93844649  1.13690284 ... -0.84403969 -1.51404894\n",
      "  -1.27174072]\n",
      " [ 1.33299838  1.06559086 -0.07658106 ... -0.04143939  1.75235415\n",
      "  -0.37706234]\n",
      " ...\n",
      " [-0.28235583 -0.93844649 -1.35748073 ... -0.13775143 -0.62126589\n",
      "  -1.09280504]\n",
      " [ 0.40993883  1.06559086 -0.25635645 ...  0.7611609   0.12300162\n",
      "   0.07027685]\n",
      " [ 0.79454698  1.06559086 -0.36871607 ...  0.7611609  -0.23298506\n",
      "  -0.2875945 ]]\n",
      "Original data: \n",
      "\n",
      "[[50.      1.     21.9    ...  3.      4.0775 77.    ]\n",
      " [34.      1.     31.4    ...  3.      3.8286 77.    ]\n",
      " [66.      2.     26.     ...  4.      5.5683 87.    ]\n",
      " ...\n",
      " [45.      1.     20.3    ...  3.88    4.3041 79.    ]\n",
      " [54.      2.     25.2    ...  5.      4.7005 92.    ]\n",
      " [59.      2.     24.7    ...  5.      4.5109 88.    ]]\n",
      "Computing for the scaled dataset\n",
      "\n",
      "Feature names in the dataset:\n",
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "\n",
      "Coefficient list after fitting the training set:\n",
      "[  0.          -9.54353432  23.40770949  10.68173657  -2.39409134\n",
      "  -0.         -13.09354774   0.          27.00282771   3.41069873]\n",
      "\n",
      "Lasso score for training dataset:\n",
      "0.524430881546436\n",
      "\n",
      "Lasso score for test dataset:\n",
      "0.45692798626144226\n",
      "\n",
      "Final feature list as computed by Lasso:\n",
      "['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_trainNew)\n",
    "X_trainScaled = scaler.transform(X_trainNew)\n",
    "print(\"Difference between scaled data and original data: \")\n",
    "print()\n",
    "print(\"Scaled data: \")\n",
    "print()\n",
    "print(X_trainScaled)\n",
    "print(\"Original data: \")\n",
    "print()\n",
    "print(X_trainNew)\n",
    "print(\"Computing for the scaled dataset\")\n",
    "print()\n",
    "print(\"Feature names in the dataset:\")\n",
    "print(diabetes.feature_names)\n",
    "print()\n",
    "lassoNew.fit(X_trainScaled,y_trainNew)\n",
    "print(\"Coefficient list after fitting the training set:\")\n",
    "print(lassoNew.coef_)\n",
    "print()\n",
    "print(\"Lasso score for training dataset:\")\n",
    "print(lassoNew.score(X_trainScaled,y_trainNew))\n",
    "print()\n",
    "print(\"Lasso score for test dataset:\")\n",
    "X_testScaled = scaler.transform(X_testNew)\n",
    "print(lassoNew.score(X_testScaled,y_testNew))\n",
    "print()\n",
    "featureListNewScaled = [ diabetes.feature_names[feature] for feature in np.where(lassoNew.coef_ != 0)[0] ] \n",
    "print(\"Final feature list as computed by Lasso:\")\n",
    "print(featureListNewScaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16209201",
   "metadata": {},
   "source": [
    "### 1.7 Observation (Task 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8e81a",
   "metadata": {},
   "source": [
    "<h4> Observation/ Discussion: </h4>\n",
    "\n",
    "From the DESCR function for the diabetes dataset we see that the data is scaled by the <b>standard deviation times n_samples</b> (i.e. the sum of squares of each column totals 1) and the data is mean centred. This leads to some features having more impact than others and Lasso eliminating features more rigorously. \n",
    "\n",
    "On the other hand, StandardScaler brings the data towards <b>a mean of 0 and a unit variance</b>, which makes all the features populate in the same space making them more or less equally impactful, thus leading to Lasso eliminating features less often and helping the model train better. \n",
    "\n",
    "The table below shows the observations for the three datasets accordingly. We can thus see that the sklearn training data returns very few features with a lower score than the scaled data which is a more complex model with a higher Lasso score.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>       \n",
    "        <td><b>Sklearn Training data</b></td>\n",
    "        <td><b>Original Unscaled data</b></td>\n",
    "        <td><b>Original Scaled data</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Test R^2 score</b></td>\n",
    "        <td>0.33115694449502453</td>\n",
    "        <td>0.46347459731826823</td>\n",
    "        <td>0.45692798626144226</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td><b>Feature list</b></td>\n",
    "        <td>['bmi', 's5']</td>\n",
    "        <td>['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's5', 's6']</td>\n",
    "        <td>['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']</td>\n",
    "    </tr>     \n",
    "</table>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ebfb7",
   "metadata": {},
   "source": [
    "### 1.8 Computing R^2 for varying alpha values (Task 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eeb6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of alpha for no features selected\n",
      "[46, 47, 48, 49]\n",
      "\n",
      "Values of alpha for 2 features selected\n",
      "[19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "\n",
      "Values of alpha for 6 features selected\n",
      "[3, 4, 5]\n",
      "\n",
      "Values of alpha for 7 features selected\n",
      "[1, 2]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbJUlEQVR4nO3dfbRddX3n8fcnF0KeCLkh4YJJIAECgZYHSUhk0WqgyArqAqEiMCKjthOxgDpdOAMzXR1LOyqtVGcsbaA8OiosFO1kMBXakmtpMJLwUCCEQLwQCYghPMUbCHn6zh97X3Jycs65557cffbdd39ea5119vP9nEP4fff57SdFBGZmVl4j8g5gZmb5ciEwMys5FwIzs5JzITAzKzkXAjOzktsn7wADNWnSpJg+fXpL627evJmxY8cObqAMFSlvkbJCsfIWKSsUK2+RssLe5X344Yc3RsTkmjMjolCv2bNnR6uWLl3a8rp5KFLeImWNKFbeImWNKFbeImWN2Lu8wMqo0666a8jMrORcCMzMSs6FwMys5FwIzMxKzoXAzKzkXAjMzErOhcDMrORcCMzMiuCaa+hcsSKTTbsQmJkVwVe+Quejj2ayaRcCM7OSK9y9hszMCmn7dtiyBd5+O3lvZrhy2rZtmUVzITCzcopgv5dfhlWrBt5AN9NwVw/v2LF3eUePpnfGjMH57FVcCMysnL7zHU655JKBrbPvvjBqFIwenbxXDx94YO3pfcP11utveL/9QGJDdzfHZvBVuBCYWTlt2JC833YbdHb233CPGgUdHblGzooLgZmV23nnwf77550iVz5ryMys5PyLwMyGry1bYOPG2q/778873ZDhQmBmxbB1K7z66u6NefV49Wvz5vrbmzCBN044gQljxrTvMwxRLgRm1n7bt8PrrzduxKtfmzbV39748ckZO5MmwUEHwbHHJsP1XhMnwj778Fh3N/OH6QHggXAhMLPW7NiR7HH39u567+3lwGXLoKencaP++uv1tzt2bNJY9zXsRx7ZuFE/8EAYObJ9n3sYciEwG+4qG+yqRrtWQ970/C1bav654ypH9tsPJk/e1Wgfemj/jfro0W35WmwXFwKzoWzbNjoffhheeaX1RrtOg12TBOPGJXvl48btGp4wAaZM2X1a9fDYsTB2LCt7epizYEHSsI8Zk2zThjQXArOh7I47OOHKK/ecPmLE7g1wX6Pc2QnTpu3ZQNdqtGs16qNG7XXD3dvdDYcdtlfbsPZyITAbyvrOeulrXPsa7UFosM36uBCYFcGsWdDVlXcKG6Z8ZbGZWcm5EJiZlZwLgZlZybkQmJmVnAuBmVnJZVoIJC2QtEbSWklXNVjuZEk7JH0syzxmZranzAqBpA7geuAs4FjgIkl7PGUtXe5a4N6sspiZWX1Z/iKYC6yNiJ6I2ArcCZxTY7krgLuBDRlmMTOzOrK8oGwK8ELF+HpgXuUCkqYA5wKnAyfX25CkhcBCgK6uLrq7u1sK1Nvb2/K6eShS3iJlheLkfc8zz3AUsGzZMrZNnJh3nKYU5buFYmWF7PJmWQhqXf8eVePfBP5rROxQg8vlI+JG4EaAOXPmxPz581sK1N3dTavr5qFIeYuUFQqUd/VqAE499dTCXFlcmO+WYmWF7PJmWQjWA9MqxqcCL1UtMwe4My0Ck4APSdoeEf+QYS4zM6uQZSFYAcyUNAN4EbgQ+A+VC0TEjL5hSbcB97gImJm1V2aFICK2S7qc5GygDuCWiFgl6dJ0/qKs/raZmTUv07uPRsQSYEnVtJoFICI+lWUWMzOrzVcWm5mVnAuBmVnJuRCYmZWcC4GZWcm5EJiZlZyfWWyWtwjo7YXXX4c33tj9vUC3P7DiciEwGwzbtiWNd3VD3vdea1rl+44ddTe9tbOTkePHt+FDWFm5EJhBsle+eXP/DXa9xn3z5sbbHzkSOjthwoTkfdIkmDlz13j1e8Xwg488wvzRozP88FZ2LgRWPtddx/F33gnS7o379u2N1xs/fvfG+sgj6zbee7yPGpX8vVZ0dLS2nlmTXAisfL7xDca99RbMmwdHHNF/Iz5hAhxwgBtkG7ZcCKyUXj3lFA758Y/zjmE2JPj0UTOzknMhMDMrORcCK5dt22DnzrxTmA0pPkZgxbNzJ7z5ZnK2z2uv7TqVs2+41rS+4d7eZBMn131EtlnpuBBYPirP22+2Me97f+ONZP16Ro1KzvaZODF5P+wwOPHE3ab9squLKe36rGZDnAuBDYrRL74Iy5YNbA9927b6G+zo2NWQd3bC5Mlw1FG7N/CV8yuHm7j46h3fusHsXS4EtvfuuYd5F19ce17lxVYTJ8LUqbUb8Opp48a1fgGWmQ2IC4HtvVdfTd5vvx2OOWZXY+6LsMwKwYXABs/v/i7MmJF3CjMbIJ8+amZWci4EZmYl50JgZlZyLgRmZiXnQmBmVnIuBGZmJedCYGZWci4EZmYl50JgZlZyLgRmZiXnQmBmVnIuBGZmJedCYGZWci4EZmYll2khkLRA0hpJayVdVWP+OZIel/SYpJWSfifLPGZmtqfMnkcgqQO4HvggsB5YIWlxRDxVsdi/AIsjIiQdD9wFzMoqk5mZ7SnLXwRzgbUR0RMRW4E7gXMqF4iI3oh3n0I+FmjwRHIzM8tClk8omwK8UDG+HphXvZCkc4GvAgcBH661IUkLgYUAXV1ddLf44PHe3t6W181DUfJ2rV7NMcDy5cvZsm5d3nGaUpTvFoqVFYqVt0hZIcO8EZHJCzgfuKli/JPAtxos/37gn/vb7uzZs6NVS5cubXndPBQm7223RUBET0/eSZpWmO82ipU1olh5i5Q1Yu/yAiujTruaZdfQemBaxfhU4KV6C0fEvwJHSJqUYSYzM6uSZSFYAcyUNEPSSOBCYHHlApKOlKR0+CRgJPBqhpnMzKzKgI4RSOoEpkXE4/0tGxHbJV0O3At0ALdExCpJl6bzFwG/D1wiaRvwNnBB+hPGzMzapN9CIKkbODtd9jHgFUk/jYg/7m/diFgCLKmatqhi+Frg2oFFNjOzwdRM19ABEbEJOA+4NSJmA2dkG8vMzNqlmUKwj6RDgI8D92Scx8zM2qyZQnANST//LyJihaTDgWezjWVmZu3S7zGCiPg+8P2K8R6Sg7xmZjYM9PuLQNJRkv5F0pPp+PGS/iT7aGZm1g7NdA39PXA1sA0gPXX0wixDmZlZ+zRTCMZExENV07ZnEcbMzNqvmUKwUdIRpHcGlfQx4FeZpjIzs7Zp5sriy4AbgVmSXgSeAz6RaSozM2ubhoUgfbjM5yLiDEljgRER8Zv2RDMzs3ZoWAgiYoek2enw5vZEMjOzdmqma+hRSYtJriV4txhExA8zS2VmZm3TTCGYSHJr6NMrpgXgQmBmNgw0c2Xxp9sRxMzM8tHMlcVTJf1I0gZJv5Z0t6Sp7QhnZmbZa+Y6gltJniz2HpIH0v+/dJqZmQ0DzRSCyRFxa0RsT1+3AZMzzmVmZm3S7JXFF0vqSF8X4+cKm5kNG80Ugs+QPJTmZZJbS3wsnWZmZsNAM2cN/ZLkmcVmZjYMNXPW0O2SJlSMd0q6JdNUZmbWNs10DR0fEW/0jUTE68B7M0tkZmZt1UwhGCGps29E0kSauyLZzMwKoJkG/TrgQUk/SMfPB/5ndpHMzKydmjlY/G1JK9l1r6HzIuKpbGOZmVm71O0akjRG0r4AacP/T8C+wKw2ZTMzszZodIzgJ8B0AElHAj8DDgcuk/S17KOZmVk7NCoEnRHxbDr8H4E7IuIK4Czgw5knMzOztmhUCKJi+HSSriEiYiuwM8tQZmbWPo0OFj8u6evAi8CRwH0AlReXmZlZ8TX6RfCfgI0kxwnOjIi30unHAl/POJeZmbVJ3V8EEfE2sMdB4Yh4EHgwy1BmZtY+zVxZbGZmw5gLgZlZyWVaCCQtkLRG0lpJV9WY/wlJj6evByWdkGUeMzPbU6MrizskfVbSn0s6tWren/S3YUkdwPUk1x0cC1wk6diqxZ4DPhARxwN/Dtw40A9gZmZ7p9EvghuAD5A8lvJ/S/rrinnnNbHtucDaiOhJrz24EzincoGIeDC9rTXAcmBq08nNzGxQNLqOYG66p46kvwH+VtIPgYsANbHtKcALFePrgXkNlv8D4B9rzZC0EFgI0NXVRXd3dxN/fk+9vb0tr5uHouTtWr2aY4Dly5ezZd26vOM0pSjfLRQrKxQrb5GyQoZ5I6LmC3i6xrQ/BZYBz9Zbr2LZ84GbKsY/CXyrzrKnAauBA/vb7uzZs6NVS5cubXndPBQm7223RUBET0/eSZpWmO82ipU1olh5i5Q1Yu/yAiujTrvaqGtopaQFVUXjGuBW0pvR9WM9MK1ifCrwUvVCko4HbgLOiYhXm9iumZkNorqFICIujoif1Jh+U0Ts28S2VwAzJc2QNBK4EFhcuYCkQ4EfAp+MiGcGFt3MzAZDvw+mkdQRETsGuuGI2C7pcuBeoAO4JSJWSbo0nb+IpKvpQJLjDwDbI2LOQP+WmZm1rmEhkLQ/cAfwkVY2HhFLgCVV0xZVDP8h8IetbNvMzAZHo+sIDgH+GZ/bb2Y2rDX6RfAA8KWIWNxgGTMzK7hGZw29TnItgJmZDWONCsF84CxJl7Upi5mZ5aDR6aObgbOB97YvjpmZtVvDs4bS00Z9Vo+Z2TA24NtQp3cl/UQWYczMrP0anT46XtLVkv5G0plKXAH0AB9vX0QzM8tSo66h/0Ny5tDPSLqHvgSMJLkn0GPZRzMzs3ZoVAgOj4jjACTdBGwEDo2I37QlmZmZtUWjYwTb+gbSg8bPuQiYmQ0/jX4RnCBpUzosYHQ6LiAiYnzm6czMLHN1C0FEdLQziJmZ5WPAp4+amdnw4kJgZlZyLgRmZiXnQmBmVnIuBGZmJedCYGZWci4EZmYl50JgZlZyLgRmZiXnQmBmVnIuBGZmJedCYGZWci4EZmYl50JgZlZyLgRmZiXnQmBmVnIuBGZmJedCYGZWci4EZmYl50JgZlZyLgRmZiWXaSGQtEDSGklrJV1VY/4sST+T9I6kK7PMYmZmte2T1YYldQDXAx8E1gMrJC2OiKcqFnsN+Dzw0axymJlZY1n+IpgLrI2InojYCtwJnFO5QERsiIgVwLYMc5iZWQOZ/SIApgAvVIyvB+a1siFJC4GFAF1dXXR3d7cUqLe3t+V181CUvF2rV3MMsHz5crasW5d3nKYU5buFYmWFYuUtUlbILm+WhUA1pkUrG4qIG4EbAebMmRPz589vKVB3dzetrpuHwuRNG//3ve99MGNGzmGaU5jvlmJlhWLlLVJWyC5vll1D64FpFeNTgZcy/HtmZtaCLAvBCmCmpBmSRgIXAosz/HtmZtaCzLqGImK7pMuBe4EO4JaIWCXp0nT+IkkHAyuB8cBOSV8Ejo2ITVnlMjOz3WV5jICIWAIsqZq2qGL4ZZIuIzMzy4mvLDYzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMys5FwIzs5JzITAzKzkXAjOzknMhMDMruX3yDmAFtXMn/PKX8PTTcP/9eacxs73gQmCNvf02PPts0uCvXp28P/00rFmTzOtb7OCDGT15co5BzaxVLgSW2LhxVyNf2eA/9xxEJMtIMH06zJoFp50GxxyTDM+axc9XrWL+uHG5fgQza40LQZns2AHr1tVu8Ddu3LXcqFFw9NFw8slwySXvNvbMnAljxuSX38wy4UIwHL39dtJ1U93gP/MMbNmya7nJk5MG/txzd9u757DDYITPIzArCxeCoopI9uIr9+r7htet29WdM2IEzJiRNPBnnrmrsZ81Cw48MN/PYGZDggvBULdjBzz/fO0G/7XXdi03ZkzSnXPKKfCZz+zenTNqVG7xzWzocyEYqq69ljk33AAvvQTvvLNreldX0sB//OO7791Pm+buHDNriQvBUHXzzezz1lvwhS/s3uB3duadzMyGGReCIezN3/otRl17bd4xzGyYc1+CmVnJuRCYmZWcu4by8s47sGEDvPwy/PrXu1594y++mBwANjPLWKaFQNIC4H8BHcBNEfG1qvlK538IeAv4VEQ8kmWmTL3zzu6NemXDXj3+xhu1tzF+fHJm0Ekn8cppp9HV1g9gZmWUWSGQ1AFcD3wQWA+skLQ4Ip6qWOwsYGb6mgf8Xfo+dFQ27vUa9b5Xo8b94IOTBv644+CMM3aNV79Gj353tY3d3W35iGZWbln+IpgLrI2IHgBJdwLnAJWF4Bzg2xERwHJJEyQdEhG/yjBXcpuF6j33eg39m2/W3sYBB+xqvI8/fvfGvLqR9wVdZjaEZVkIpgAvVIyvZ8+9/VrLTAEGvxAsWcLcSy+FTZvqN+4TJuzeuJ955p577AcfDAcd5MbdzIaNLAuBakyLFpZB0kJgIUBXVxfdLXSZ7P/88xxy2GG8NnkyWydOZFtnJ1snTmRrZydbOzvZ1tnJzpEjG2/krbegpyd5tUFvb29LnzUPRcoKxcpbpKxQrLxFygoZ5o2ITF7AKcC9FeNXA1dXLXMDcFHF+BrgkEbbnT17drRq6dKlLa+bhyLlLVLWiGLlLVLWiGLlLVLWiL3LC6yMOu1qltcRrABmSpohaSRwIbC4apnFwCVKvA94M7I+PmBmZrvJrGsoIrZLuhy4l+T00VsiYpWkS9P5i4AlJKeOriU5ffTTWeUxM7PaMr2OICKWkDT2ldMWVQwHcFmWGczMrDHfYsLMrORcCMzMSs6FwMys5FwIzMxKzoXAzKzklJy4UxySXgHWtbj6JGDjIMbJWpHyFikrFCtvkbJCsfIWKSvsXd7DImJyrRmFKwR7Q9LKiJiTd45mFSlvkbJCsfIWKSsUK2+RskJ2ed01ZGZWci4EZmYlV7ZCcGPeAQaoSHmLlBWKlbdIWaFYeYuUFTLKW6pjBGZmtqey/SIwM7MqLgRmZiVXmkIgaYGkNZLWSroq7zyNSLpF0gZJT+adpT+SpklaKmm1pFWSvpB3pnokjZL0kKR/T7P+Wd6ZmiGpQ9Kjku7JO0sjkp6X9ISkxyStzDtPf9JnpP9A0tPpv99T8s5Ui6Sj0++077VJ0hcH9W+U4RiBpA7gGeCDJM9FXkHyZLSncg1Wh6T3A73AtyPit/PO04ikQ0ieKveIpP2Bh4GPDsXvVpKAsRHRK2lf4N+AL0TE8pyjNSTpj4E5wPiI+EjeeeqR9DwwJyIKcYGWpNuBByLipvThWWMi4o2cYzWUtmUvAvMiotULa/dQll8Ec4G1EdETEVuBO4Fzcs5UV0T8K/Ba3jmaERG/iohH0uHfAKuBKfmmqi19Yl9vOrpv+hrSe0KSpgIfBm7KO8twImk88H7gZoCI2DrUi0Dq94BfDGYRgPIUginACxXj6xmijVWRSZoOvBf4ec5R6kq7WR4DNgD/FBFDNmvqm8B/AXbmnKMZAdwn6WFJC/MO04/DgVeAW9Nut5skjc07VBMuBO4Y7I2WpRCoxrQhvSdYNJLGAXcDX4yITXnnqScidkTEicBUYK6kIdv1JukjwIaIeDjvLE06NSJOAs4CLku7OIeqfYCTgL+LiPcCm4GhfuxwJHA28P3B3nZZCsF6YFrF+FTgpZyyDDtpf/vdwHcj4od552lG2g3QDSzIN0lDpwJnp33vdwKnS/pOvpHqi4iX0vcNwI9IumSHqvXA+opfhD8gKQxD2VnAIxHx68HecFkKwQpgpqQZaVW9EFicc6ZhIT0AezOwOiL+Ou88jUiaLGlCOjwaOAN4OtdQDUTE1RExNSKmk/ybvT8iLs45Vk2SxqYnC5B2sZwJDNmz3iLiZeAFSUenk34PGHInOFS5iAy6hSDjh9cPFRGxXdLlwL1AB3BLRKzKOVZdku4A5gOTJK0H/kdE3JxvqrpOBT4JPJH2vQP8t4hYkl+kug4Bbk/PvBgB3BURQ/qUzALpAn6U7BewD/C9iPhJvpH6dQXw3XTnsAf4dM556pI0huSsx89msv0ynD5qZmb1laVryMzM6nAhMDMrORcCM7OScyEwMys5FwIzs5JzIbAhQVJIuq5i/EpJXx6kbd8m6WODsa1+/s756V0sl9aY91fpHU//qoXtnijpQ4OT0mxPLgQ2VLwDnCdpUt5BKqXXHDTrD4A/iojTasz7LHBSRHyphRgnAgMqBEr4/29riv+h2FCxneR5rP+5ekb1Hr2k3vR9vqSfSrpL0jOSvibpE+kzB56QdETFZs6Q9EC63EfS9TvSPfUVkh6X9NmK7S6V9D3giRp5Lkq3/6Ska9Npfwr8DrCoeq9f0mJgLPBzSRekVzjfnf7dFZJOTZebK+nB9CZoD6b3oR8JXANckN6L/gJJX5Z0ZcX2n5Q0PX2tlvS3wCPANElfqvh8f5YuP1bSj5U8l+FJSRcM9D+WDS+luLLYCuN64HFJfzmAdU4AjiG5bXcPcFNEzFXygJwrgC+my00HPgAcASyVdCRwCfBmRJwsaT9gmaT70uXnAr8dEc9V/jFJ7wGuBWYDr5PcbfOjEXGNpNOBKyNit4eyRMTZknrTm92RFphvRMS/STqU5Ir3Y0hud/H+9Er4M4CvRMTvp0VmTkRcnq7/5Qbfx9HApyPijySdCcxMP4uAxemN4CYDL0XEh9PtHdDvt2zDmguBDRkRsUnSt4HPA283udqKiPgVgKRfAH0N+RNAZRfNXRGxE3hWUg8wi+R+OMdX/No4gKTh3Ao8VF0EUicD3RHxSvo3v0tyX/t/aDIvJPc4Oja9HQPA+PQ+PQeQ3AJjJsndcfcdwDb7rKt40M6Z6evRdHwcyed7APh6+mvmnoh4oIW/Y8OIC4ENNd8k6da4tWLadtJuzPQmdyMr5r1TMbyzYnwnu//7rr6XSpDsJV8REfdWzpA0n+S2xLXUuqX5QI0ATomI3YqdpG8BSyPiXCXPduius/6730dqVMVwZW4BX42IG6o3IGk2yXGHr0q6LyKuGfCnsGHDxwhsSImI14C7SA689nmepCsGkifLtbKnfL6kEelxg8OBNSRdMp9TchttJB2l/h9O8nPgA5ImpQeSLwJ+OsAs9wGX941IOjEdPIDkMYQAn6pY/jfA/hXjz5PeMlnSScCMOn/nXuAzSp4VgaQpkg5Ku7feiojvAF9n6N9+2TLmQmBD0XVA5dlDf0/S+D4EzKP+3noja0ga7H8ELo2ILSSPf3wKeETSk8AN9PMrOe2GuhpYCvw7yf3h/+8As3wemJMewH0KuDSd/pcke+jLSO6S22cpSVfSY+mB3buBiUru9vo5kudx18p6H/A94GeSniC55/7+wHHAQ+n6/x34iwHmt2HGdx81Mys5/yIwMys5FwIzs5JzITAzKzkXAjOzknMhMDMrORcCM7OScyEwMyu5/w+tlgu85HixHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "featureList, scoreList, features2, features0, features6, features7 = [],[],[],[],[],[]\n",
    "\n",
    "for alpha in range(1,50):\n",
    "    lassoAlpha = Lasso(alpha = alpha)\n",
    "    lassoAlpha.fit(X_trainScaled,y_trainNew)\n",
    "    scoreList.append(lassoAlpha.score(X_testScaled,y_testNew))\n",
    "    featureList.append(np.sum(lassoAlpha.coef_!= 0))\n",
    "    if np.sum(lassoAlpha.coef_!= 0) == 0:\n",
    "        features0.append(alpha)\n",
    "    if np.sum(lassoAlpha.coef_!= 0) == 2:\n",
    "        features2.append(alpha) \n",
    "    if np.sum(lassoAlpha.coef_!= 0) == 6:\n",
    "        features6.append(alpha)        \n",
    "    if np.sum(lassoAlpha.coef_!= 0) == 7:\n",
    "        features7.append(alpha)                \n",
    "    \n",
    "X = featureList\n",
    "y = scoreList\n",
    "plt.xlabel('Number of features ')\n",
    "plt.ylabel('R^2 Scores')\n",
    "plt.grid()\n",
    "plt.plot(X, y,'r-')\n",
    "\n",
    "print(\"Values of alpha for no features selected\")\n",
    "print(features0)\n",
    "print()\n",
    "\n",
    "print(\"Values of alpha for 2 features selected\")\n",
    "print(features2)\n",
    "print()\n",
    "\n",
    "print(\"Values of alpha for 6 features selected\")\n",
    "print(features6)\n",
    "print()\n",
    "\n",
    "print(\"Values of alpha for 7 features selected\")\n",
    "print(features7)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6944dbb",
   "metadata": {},
   "source": [
    "The graph displays an increasing value for the Lasso score as the number of features increases. For higher number of features the values of alpha tend to decrease (between 1 and 2) whereas for lesser number of features the value for alpha increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddd316",
   "metadata": {},
   "source": [
    "### 1.9 Obtaining optimum alpha using cross validation (Task 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7889e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value for alpha: \n",
      "1.460000000000001\n",
      "\n",
      "Optimal Lasso score for training dataset:\n",
      "0.522978902030274\n",
      "\n",
      "Optimal Lasso score for test dataset:\n",
      "0.4541159676120279\n",
      "\n",
      "Number of features :\n",
      "7\n",
      "\n",
      "Optimal Final feature list as computed by Lasso using CV:\n",
      "['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimalScore = np.NINF\n",
    "alpha = optimalAlpha = 0.01\n",
    "\n",
    "while alpha < 5:\n",
    "    calculatedLasso = Lasso(alpha = alpha)\n",
    "    calculatedLasso.fit(X_trainScaled, y_trainNew)\n",
    "    calculatedScoreList = cross_val_score(calculatedLasso, X_trainScaled, y_trainNew, cv = 5)\n",
    "    calculatedScore = np.mean(calculatedScoreList)\n",
    "    if calculatedScore > optimalScore:\n",
    "        optimalScore = calculatedScore\n",
    "        optimalAlpha = alpha\n",
    "    alpha += 0.01\n",
    "\n",
    "print(\"Optimal value for alpha: \")\n",
    "print(optimalAlpha)\n",
    "print()\n",
    "optimalLasso = Lasso(alpha = optimalAlpha)\n",
    "optimalLasso.fit(X_trainScaled, y_trainNew)\n",
    "optimalLassoScoreTrain = optimalLasso.score(X_trainScaled, y_trainNew)\n",
    "optimalLassoScoreTest = optimalLasso.score(X_testScaled, y_testNew)\n",
    "noOfFeatures = np.sum(optimalLasso.coef_!= 0)\n",
    "optimalFeatureList = [ diabetes.feature_names[feature] for feature in np.where(optimalLasso.coef_ != 0)[0] ] \n",
    "\n",
    "print(\"Optimal Lasso score for training dataset:\")\n",
    "print(optimalLassoScoreTrain)\n",
    "print()\n",
    "print(\"Optimal Lasso score for test dataset:\")\n",
    "print(optimalLassoScoreTest)\n",
    "print()\n",
    "print(\"Number of features :\")\n",
    "print(noOfFeatures)\n",
    "print()\n",
    "featureListLasso = [ diabetes.feature_names[feature] for feature in np.where(optimalLasso.coef_ != 0)[0] ] \n",
    "print(\"Optimal Final feature list as computed by Lasso using CV:\")\n",
    "print(featureListLasso)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11be64",
   "metadata": {},
   "source": [
    "The above observation confirms our observations from Task 9. The optimal value for alpha lies between 1 and 2 (1.46) with teh number of features as 7.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf97f10",
   "metadata": {},
   "source": [
    "# 2. Implementing the inductive conformal predictor (Task 11)\n",
    "\n",
    "### 2.1 Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c458546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainProper, X_calibration, y_trainProper, y_calibration = \\\n",
    "train_test_split( X_trainNew, y_trainNew, test_size = 99, random_state = 2110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08985d24",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a3e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibScaler = StandardScaler()\n",
    "calibScaler.fit(X_trainProper)\n",
    "X_trainProperScaled = calibScaler.transform(X_trainProper)\n",
    "X_calibrationScaled = calibScaler.transform(X_calibration)\n",
    "X_testNewScaled = calibScaler.transform(X_testNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef15ba",
   "metadata": {},
   "source": [
    "### 2.3 Calculating prediction intervals and error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad23ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalCalibScore = np.NINF\n",
    "alphaCalib = optimalCalibAlpha = 0.01\n",
    "\n",
    "while alphaCalib < 5:\n",
    "    calculatedCalibLasso = Lasso(alpha = alphaCalib)\n",
    "    calculatedCalibLasso.fit(X_trainProperScaled, y_trainProper)\n",
    "    calculatedScoreCalibList = cross_val_score(calculatedCalibLasso, X_trainProperScaled, y_trainProper, cv = 5)\n",
    "    calculatedCalibScore = np.mean(calculatedScoreCalibList)\n",
    "    if calculatedCalibScore > optimalCalibScore:\n",
    "        optimalCalibScore = calculatedCalibScore\n",
    "        optimalCalibAlpha = alphaCalib\n",
    "    alphaCalib += 0.01\n",
    "\n",
    "finalCalibLasso = Lasso(alpha = optimalCalibAlpha)\n",
    "finalCalibLasso.fit(X_trainProperScaled, y_trainProper)\n",
    "y_calibrationPredicted = finalCalibLasso.predict(X_calibrationScaled)\n",
    "nonConformityScores = np.sort([abs(y_calibration[i] - y_calibrationPredicted[i]) for i in range(len(y_calibration))])\n",
    "kfor5 = np.ceil((1 - 0.05) * (1 + len(nonConformityScores)))\n",
    "kfor20 = np.ceil((1 - 0.2) * (1 + len(nonConformityScores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069fe335",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaForK5 = nonConformityScores[int(kfor5)]\n",
    "alphaForK20 = nonConformityScores[int(kfor20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e5d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval lengths for K5: \n",
      "[219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.6056772539491, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907]\n",
      "\n",
      "Interval lengths for K20: \n",
      "[155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.2054731590397, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974]\n",
      "\n",
      "Error rate for K5: \n",
      "0.04504504504504503\n",
      "\n",
      "Error rate for K20: \n",
      "0.16216216216216217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_testPredicted = finalCalibLasso.predict(X_testNewScaled)\n",
    "\n",
    "intervalsForK5 = [ [y_testPredicted[i] - alphaForK5, y_testPredicted[i] + alphaForK5] for i in range(len(y_testPredicted))]\n",
    "intervalsForK20 = [ [y_testPredicted[i] - alphaForK20, y_testPredicted[i] + alphaForK20] for i in range(len(y_testPredicted))]\n",
    "\n",
    "intervalLengthsK5 = [ item[1] - item[0] for item in intervalsForK5]\n",
    "intervalLengthsK20 = [ item[1] - item[0] for item in intervalsForK20]\n",
    "\n",
    "errorRatesListForK5 = [ True if intervalsForK5[i][0] <= y_testNew[i] <= intervalsForK5[i][1] else False for i in range(len(y_testNew)) ]\n",
    "errorRatesListForK20 = [ True if intervalsForK20[i][0] <= y_testNew[i] <= intervalsForK20[i][1] else False for i in range(len(y_testNew)) ]\n",
    "\n",
    "errorRateForK5 = 1 - (sum(np.array(errorRatesListForK5, dtype=bool))/len(errorRatesListForK5))\n",
    "errorRateForK20 = 1 - (sum(np.array(errorRatesListForK20, dtype=bool))/len(errorRatesListForK20))\n",
    "\n",
    "print(\"Interval lengths for K5: \")\n",
    "print(intervalLengthsK5)\n",
    "print()\n",
    "print(\"Interval lengths for K20: \")\n",
    "print(intervalLengthsK20)\n",
    "print()\n",
    "\n",
    "print(\"Error rate for K5: \")\n",
    "print(errorRateForK5)\n",
    "print()\n",
    "print(\"Error rate for K20: \")\n",
    "print(errorRateForK20)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70fcbae",
   "metadata": {},
   "source": [
    "# 3. Conclusions and obtained values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d003f6",
   "metadata": {},
   "source": [
    "<b> 1. The training and test R2 for the Lasso model with default parameters on the scikit-learn version of diabetes and the number of features used. </b>\n",
    "\n",
    "Lasso score for training dataset:\n",
    "0.3779757862584656\n",
    "\n",
    "Lasso score for test dataset:\n",
    "0.33115694449502453\n",
    "\n",
    "Final feature list as computed by Lasso:\n",
    "['bmi', 's5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234111c7",
   "metadata": {},
   "source": [
    "<b> 2. The training and test R2 for the Lasso model with default parameters on the original version of diabetes and the number of features used. </b>\n",
    "\n",
    "Lasso score for training dataset:\n",
    "0.5226383603039815\n",
    "\n",
    "Lasso score for test dataset:\n",
    "0.46347459731826823\n",
    "\n",
    "Final feature list as computed by Lasso:\n",
    "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's5', 's6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87f6e9",
   "metadata": {},
   "source": [
    "<b> 3. The training and test R2 for the Lasso model with default parameters on your version of diabetes (i.e., on the original version of diabetes with the features normalized by you); the number of features used. </b>\n",
    "\n",
    "Lasso score for training dataset:\n",
    "0.524430881546436\n",
    "\n",
    "Lasso score for test dataset:\n",
    "0.45692798626144226\n",
    "\n",
    "Final feature list as computed by Lasso:\n",
    "['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019b04e",
   "metadata": {},
   "source": [
    "<b> 4. The training and test R2 for the Lasso model with the best parameters chosen by cross-validation on your version of diabetes; the number of features used. </b>\n",
    "\n",
    "Optimal value for alpha: \n",
    "1.460000000000001\n",
    "\n",
    "Optimal Lasso score for training dataset:\n",
    "0.522978902030274\n",
    "\n",
    "Optimal Lasso score for test dataset:\n",
    "0.4541159676120279\n",
    "\n",
    "Number of features :\n",
    "7\n",
    "\n",
    "Optimal Final feature list as computed by Lasso using CV:\n",
    "['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63cb21",
   "metadata": {},
   "source": [
    "<b> 5. The lengths of prediction intervals and their test error rates at signifi- cance levels 5% and 20% (if you are implementing an inductive conformal predictor). </b>\n",
    "\n",
    "Interval lengths for K5: \n",
    "[219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.6056772539491, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.6056772539491, 219.60567725394907, 219.60567725394907, 219.60567725394904, 219.60567725394907, 219.60567725394904, 219.60567725394907]\n",
    "\n",
    "Interval lengths for K20: \n",
    "[155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.2054731590397, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.2054731590397, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903974, 155.20547315903977, 155.20547315903974]\n",
    "\n",
    "Error rate for K5: \n",
    "0.04504504504504503\n",
    "\n",
    "Error rate for K20: \n",
    "0.16216216216216217\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
